This article reports on recovering keystrokes typed on a keyboard from a sound
recording of the user typing. Emanations produced by electronic devices have
long been a topic of concern in the security and privacy communities [Briol
1991]. Both electromagnetic and optical emanations have been used as sourcesfor attacks. For example, Kuhn [2002, 2003] was able to recover the display on
CRT and LCD monitors using indirectly reflected optical emanations. Acoustic
emanations are another source of data for attacks. Researchers have shown
that acoustic emanations of matrix printers carry substantial information about
the printed text [Briol 1991]. Some researchers suggest it may be possible to
discover CPU operations from acoustic emanations [Shamir and Tromer 2004].
In ground-breaking research, Asonov and Agrawal [2004] showed that it is
possible to recover text from the acoustic emanations from typing on a keyboard.
Most emanations, including acoustic keyboard emanations, are not uniform
across different instances, even when the same device model is used; and they
are affected by the environment. Different users on a single keyboard or different
keyboards (even of the same model) emit different sounds, making reliable
recognition hard [Asonov and Agrawal 2004]. Asonov and Agrawal achieved a
relatively high recognition rate (approximately 80%) when they trained neural
networks with text-labeled sound samples of the same user typing on the
same keyboard. Their attack is analogous to a known plaintext attack on a
cipherâ€”the cryptanalyst has a sample of plaintext (the keys typed) and the
corresponding ciphertext (the recording of acoustic emanations). This labeled
training sample requirement suggests a limited attack because the attacker
needs to obtain training samples of significant length. Presumably, these could
be obtained from video surveillance or network sniffing. However, video surveillance,
in most cases, should render the acoustic attack irrelevant because, even
if passwords are masked on the screen, a video shot of the keyboard could directly
reveal the keys being typed.
In this article, we argue that a labeled training sample requirement is unnecessary
for an attacker. This implies keyboard emanation attacks are more
serious than previous work suggests. The key insight in our work is that the
typed text is often not random. When one types English text, the finite number
of mostly used English words limits possible temporal combinations of keys, and
English grammar limits word combinations. One can first cluster (using unsupervised
methods) keystrokes into a number of acoustic classes based on their
sound. Given sufficient (unlabeled) training samples, a most-likely mapping
between these acoustic classes and actual typed characters can be established
using the language constraints.
This task is not trivial. Challenges include: (i) How can one mathematically
model language constraints and mechanically apply them? (ii) In the first
sound-based clustering step, how can one address the problem of different keys
clustered in the same acoustic class and a single key clustered in multiple acoustic
classes? (iii) Can we improve the accuracy of the guesses by the algorithm
to match the level achieved with labeled samples?
Our work answers these challenges, using a combination of machine learning
and speech recognition techniques.We show how to build a keystroke recognizer
that has better recognition rate than labeled sample recognizers in Asonov and
Agrawal [2004]. We only use a sound recording of a user typing.
Our method can be viewed as a machine learning version of classic attacks to
simple substitution ciphers. Assuming the ideal case in which a key producesexactly the same sound each time it is pressed, each keystroke could be easily
given an acoustic class according to the sound. The acoustic class assignment
would be a permutation of the key labels. This is exactly an instance of substitution
cipher. Early cryptographers developed methods for cryptanalyzing substitution
ciphers. Our attack can be viewed as an extension of these methods,
but our problem is more difficult because the sound of a particular keystroke
varies even when it is produced by the same typist.
We built a prototype that can bootstrap the recognizer from about 10 minutes
of English text typing, using about 30 minutes of computation on a desktop
computer with a Pentium IV 3.0G CPU and 1GB of memory. After the bootstrap
step, it could recognize language-independent keystrokes in real time, including
random keystrokes occurring in passwords, with an accuracy rate of about 90%.
When language-dependent constraints are applied to English text, we achieve
a 90% to 96% accuracy rate for characters and a 75% to 90% accuracy rate for
words.1
We posit that our framework also applies to other types of emanations with
inherent statistical constraints, such as power consumption or electromagnetic
radiation. One only needs to adapt the methods of extracting features and
modeling constraints. Our work implies that emanation attacks are far more
challenging, serious, and realistic than previously realized. Emanation attacks
deserve greater attention in the computer security community.
This article is organized as follows: Section 2 briefly reviews previous keyboard
emanation attacks. Section 3 presents an informal description of the new
attack, followed by additional details in Section 4. Section 5 presents experiment
results. Section 6 discusses issues and future work. Section 7 concludes
the article.